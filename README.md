🚢 TITANIC_ETL - Data Pipeline Project

📌 Overview

TITANIC_ETL is a data pipeline project that processes the Titanic dataset using Apache Airflow. It follows ETL (Extract, Transform, Load) principles to automate data ingestion, cleaning, transformation, and storage.

🏗 Project Structure

TITANIC_ETL/
├── dags/                  # Airflow DAGs for workflow automation
├── pipeline/              # ETL scripts for data processing
├── src/                   # Core source code
├── notebook/              # Jupyter notebooks for analysis
├── config/                # Configuration files
├── logs/                  # Logs for debugging
├── tests/                 # Unit tests for validation
├── Dockerfile             # Containerization setup
├── requirements.txt       # Python dependencies
└── README.md              # Project documentation

🚀 Features

✅ Automated ETL Pipeline using Apache Airflow✅ Scalable & Configurable architecture✅ Docker Support for easy deployment
